{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "505d1043",
   "metadata": {},
   "source": [
    "# Make the dataset features Numerical(make suitable for Logistic Regression model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bfec22",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the datasets (make sure to upload them to Colab)\n",
    "hospital_1_df = pd.read_csv('old_csv/HOSPITAL_1.csv')\n",
    "hospital_2_df = pd.read_csv('old_csv/HOSPITAL_2.csv')\n",
    "\n",
    "# List of 17 selected features for the target column \"dialysis_encoded\"\n",
    "selected_features = [\n",
    "    'Age of the patient', 'Blood pressure (mm/Hg)', 'Albumin in urine', 'Sugar in urine',\n",
    "    'Random blood glucose level (mg/dl)', 'Body Mass Index (BMI)', 'Physical activity level',\n",
    "    'Duration of diabetes mellitus (years)', 'Duration of hypertension (years)', 'Cystatin C level',\n",
    "    'C-reactive protein (CRP) level', 'Interleukin-6 (IL-6) level', 'Red blood cells in urine',\n",
    "    'Pus cells in urine', 'Pus cell clumps in urine', 'Bacteria in urine', 'Pedal edema (yes/no)'\n",
    "]\n",
    "\n",
    "# Select only the relevant features and include the target column\n",
    "hospital_1_selected = hospital_1_df[selected_features + ['dialysis_encoded']]\n",
    "hospital_2_selected = hospital_2_df[selected_features + ['dialysis_encoded']]\n",
    "\n",
    "# Convert categorical values to numeric using LabelEncoder for categorical columns\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Function to convert categorical columns to numeric\n",
    "def convert_categorical_to_numeric(df):\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col] = encoder.fit_transform(df[col].astype(str))\n",
    "    return df\n",
    "\n",
    "# Apply conversion to both datasets\n",
    "hospital_1_selected_numeric = convert_categorical_to_numeric(hospital_1_selected)\n",
    "hospital_2_selected_numeric = convert_categorical_to_numeric(hospital_2_selected)\n",
    "\n",
    "# Save the transformed datasets as new CSV files\n",
    "hospital_1_selected_numeric.to_csv('HOSPITAL_1_transformed_with_target.csv', index=False)\n",
    "hospital_2_selected_numeric.to_csv('HOSPITAL_2_transformed_with_target.csv', index=False)\n",
    "\n",
    "# Download the transformed files\n",
    "from google.colab import files\n",
    "files.download('HOSPITAL_1_transformed_with_target.csv')\n",
    "files.download('HOSPITAL_2_transformed_with_target.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d29db28",
   "metadata": {},
   "source": [
    "Project Exhibision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee84de6",
   "metadata": {},
   "source": [
    "# Step 1: Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3423681d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# For data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For model training\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# For encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b64cfa",
   "metadata": {},
   "source": [
    "# Step 2: Load Datasets and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e18bab6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load the two hospital datasets\n",
    "hospital_1 = pd.read_csv('new_csv/HOSPITAL_1_transformed_with_target.csv')\n",
    "hospital_2 = pd.read_csv('new_csv/HOSPITAL_2_transformed_with_target.csv')\n",
    "\n",
    "# Separate features and target for both hospitals\n",
    "X_1 = hospital_1.drop(columns=['dialysis_encoded'])\n",
    "y_1 = hospital_1['dialysis_encoded']\n",
    "\n",
    "X_2 = hospital_2.drop(columns=['dialysis_encoded'])\n",
    "y_2 = hospital_2['dialysis_encoded']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cdcda5",
   "metadata": {},
   "source": [
    "# Step 3: Train Logistic Regression Model for Each Hospital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7a7e7e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialize Logistic Regression models for both hospitals\n",
    "model_1 = LogisticRegression(max_iter=1000000)\n",
    "model_2 = LogisticRegression(max_iter=1000000)\n",
    "\n",
    "# Initialize the SimpleImputer to replace missing values with the mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Apply imputation to both datasets\n",
    "X_1_imputed = imputer.fit_transform(X_1)\n",
    "X_2_imputed = imputer.fit_transform(X_2)\n",
    "\n",
    "# Train-test split for better generalization (optional, can skip if you don't want to split)\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_1_imputed, y_1, test_size=0.2, random_state=42)\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2_imputed, y_2, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the models\n",
    "model_1.fit(X_train_1, y_train_1)\n",
    "model_2.fit(X_train_2, y_train_2)\n",
    "\n",
    "# Predict on the test set (you can also predict on the training set if preferred)\n",
    "y_pred_1 = model_1.predict(X_test_1)\n",
    "y_pred_2 = model_2.predict(X_test_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2becd50c",
   "metadata": {},
   "source": [
    "# Step 4: Evaluate Models for Each Hospital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47f9981",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the models (optional)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(f\"Accuracy for Hospital 1: {accuracy_score(y_test_1, y_pred_1)}\")\n",
    "print(f\"Accuracy for Hospital 2: {accuracy_score(y_test_2, y_pred_2)}\")\n",
    "\n",
    "# Confusion Matrix for Hospital 1\n",
    "conf_matrix_1 = confusion_matrix(y_test_1, y_pred_1)\n",
    "print(f\"Confusion Matrix for Hospital 1: \\n{conf_matrix_1}\")\n",
    "\n",
    "# Confusion Matrix for Hospital 2\n",
    "conf_matrix_2 = confusion_matrix(y_test_2, y_pred_2)\n",
    "print(f\"Confusion Matrix for Hospital 2: \\n{conf_matrix_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a83675c",
   "metadata": {},
   "source": [
    "# Step 5: Federated Learning Concept (Combining the Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea26b60",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Step 5: Federated Learning Concept (Combining the Models)\n",
    "# Instead of directly assigning weights, we will handle model parameters appropriately.\n",
    "\n",
    "# Initialize Logistic Regression models for both hospitals\n",
    "model_1 = LogisticRegression(max_iter=1000)\n",
    "model_2 = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the models on their respective datasets (assuming X_train_1, y_train_1, X_train_2, y_train_2 are already defined)\n",
    "model_1.fit(X_train_1, y_train_1)\n",
    "model_2.fit(X_train_2, y_train_2)\n",
    "\n",
    "# Get coefficients (weights) from both models\n",
    "weights_1 = model_1.coef_\n",
    "weights_2 = model_2.coef_\n",
    "\n",
    "# Calculate the average weight (simple average of model coefficients)\n",
    "average_weights = (weights_1 + weights_2) / 2\n",
    "\n",
    "# Create a new Logistic Regression model (central model)\n",
    "central_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Instead of directly setting the coef_, we fit the central model with the average weights\n",
    "# We simulate setting the coefficients by using the coefficients as a starting point:\n",
    "central_model.fit(X_train_1, y_train_1)  # Fit it once to initialize the model\n",
    "central_model.coef_ = average_weights  # Directly modify the coefficients (not recommended for general use, but works for this example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dd49a9",
   "metadata": {},
   "source": [
    "# Step 6: Evaluate Central Model (Federated Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7906bc45",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Step 6: Evaluate Central Model (Federated Model)\n",
    "# We will use X_test_1 for evaluation (you can use X_test_2 for Hospital 2 as well)\n",
    "y_pred_central = central_model.predict(X_test_1)\n",
    "\n",
    "# Evaluate the central model's performance\n",
    "accuracy_central = accuracy_score(y_test_1, y_pred_central)\n",
    "conf_matrix_central = confusion_matrix(y_test_1, y_pred_central)\n",
    "\n",
    "print(f\"Central Model Accuracy: {accuracy_central}\")\n",
    "print(f\"Confusion Matrix for Central Model: \\n{conf_matrix_central}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3aa116",
   "metadata": {},
   "source": [
    "# Step 7: Save the Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd664ca0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save individual models\n",
    "joblib.dump(model_1, 'hospital_1_model.pkl')\n",
    "joblib.dump(model_2, 'hospital_2_model.pkl')\n",
    "\n",
    "# Save central model\n",
    "joblib.dump(central_model, 'central_model.pkl')\n",
    "\n",
    "from google.colab import files\n",
    "# files.download('central_model.pkl')\n",
    "# files.download('hospital_1_model.pkl')\n",
    "files.download('hospital_2_model.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3481b030",
   "metadata": {},
   "source": [
    "# 1. Define the Testing Features (Input) and Target (Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06be792",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Prepare the Input (Features)\n",
    "# We use the test set we created earlier (X_test_1 or X_test_2)\n",
    "X_test_input = X_test_1\n",
    "\n",
    "# 2. Prepare the Ground Truth (Actual Output)\n",
    "y_test_actual = y_test_1\n",
    "\n",
    "# 3. Generate Model Predictions\n",
    "y_pred_central = central_model.predict(X_test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01b160d",
   "metadata": {},
   "source": [
    "# 2. Generate Accuracy and Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739d717f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(y_test_actual, y_pred_central)\n",
    "\n",
    "print(f\"--- Federated Central Model Performance ---\")\n",
    "print(f\"Overall Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_test_actual, y_pred_central))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
